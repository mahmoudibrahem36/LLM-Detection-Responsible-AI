# LLM Detection using Responsible AI

This project addresses the challenge of detecting text generated by Large Language Models (LLMs) using ethical and Responsible AI techniques.

## Key Features:
- Models: BERT, GPT, LSTM
- Embeddings: GloVe, FastText
- Explainability: SHAP, LIME
- Robustness: Adversarial Testing, Monte Carlo Dropout
- Privacy: Differential Privacy techniques
- Evaluation: Cross-validation, Ensemble learning

## Results:
- Accuracy: 99.58%
- Precision: 99.30%
- Recall: 99.55%
- AUC: 99.98%

## Structure:
- `data/` â€“ Dataset files
- `notebooks/` â€“ Jupyter notebooks for training and analysis
- `src/` â€“ Core model and preprocessing code
- `results/` â€“ Plots, metrics, and saved models
- `docs/` â€“ Additional documentation

## ðŸ§ª Citation:
If you use this project, please cite the corresponding research paper (link here).

## ðŸ“¬ Contact:
Mahmoud Ibrahim â€“ [LinkedIn](https://www.linkedin.com/in/mahmoud-ibrahem-688936109/)
